{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessing.ipynb","provenance":[],"mount_file_id":"1ChpIbf2O5h4_WlcfPp-XGwZ2tkDenkMC","authorship_tag":"ABX9TyOqdpgp4PyMbhXtrY4LPrhd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HEGolzhYDpMY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618085551377,"user_tz":-330,"elapsed":5541,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}},"outputId":"e6a85c5e-143b-4dd3-ecb5-5be7d146a1c6"},"source":["import pickle\n","import spacy\n","import os\n","import re, string, unicodedata\n","import nltk\n","!pip install contractions\n","!pip install inflect\n","import contractions\n","import inflect\n","from bs4 import BeautifulSoup\n","from nltk import word_tokenize, sent_tokenize\n","from nltk.corpus import stopwords,wordnet\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.48)\n","Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n","Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.1.7)\n","Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n","Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (2.1.0)\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"ecgzA6gwExdE","executionInfo":{"status":"ok","timestamp":1618085554335,"user_tz":-330,"elapsed":936,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}}},"source":["def DoctoDict():\n","  file_Names = os.listdir(\"/content/drive/MyDrive/IR_ASSIGNMENT_1/stories1\")\n","  file_Paths = []\n","  for i in range(len(file_Names)):\n","    file_Paths.append(\"/content/drive/MyDrive/IR_ASSIGNMENT_1/stories1/\"+file_Names[i])\n","  corpus = {}\n","  for i in range(len(file_Paths)):\n","    with open(file_Paths[i],encoding = \"latin-1\") as f_input:\n","      corpus[file_Names[i]] = [f_input.read()]\n","  return corpus"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"DVYdVrsbI7JJ","executionInfo":{"status":"ok","timestamp":1618085646053,"user_tz":-330,"elapsed":91050,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}}},"source":["CORPUS = DoctoDict()\n","with open('CORPUS.pickle', 'wb') as handle:\n","  pickle.dump(CORPUS, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICteejq_wa7a","executionInfo":{"status":"ok","timestamp":1618085654191,"user_tz":-330,"elapsed":857,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}},"outputId":"fe4b75a8-8d1a-4f41-dc3d-a23ed653eea3"},"source":["with open('/content/CORPUS.pickle', 'rb') as handle:\n","  corpus = pickle.load(handle)\n","\n","len(corpus.keys())"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["467"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"eM6mJ8drTPNA","executionInfo":{"status":"ok","timestamp":1618085656323,"user_tz":-330,"elapsed":974,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}}},"source":["def strip_html(text):\n","    soup = BeautifulSoup(text, \"html.parser\")\n","    return soup.get_text()\n","\n","def remove_between_square_brackets(text):\n","    text=re.sub('\\n',' ',text)\n","    return re.sub('\\[[^]]*\\]', '', text)\n","\n","def denoise_text(text):\n","    text = strip_html(text)\n","    text = remove_between_square_brackets(text)\n","    return text\n","\n","def replace_contractions(text):\n","    return contractions.fix(text)\n","\n","def remove_non_ascii(words):\n","    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n","    new_words = []\n","    for word in words:\n","        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n","        new_words.append(new_word)\n","    return new_words\n","\n","def to_lowercase(words):\n","    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n","    new_words = []\n","    for word in words:\n","        new_word = word.lower()\n","        new_words.append(new_word)\n","    return new_words\n","\n","def remove_punctuation(words):\n","    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n","    new_words = []\n","    for word in words:\n","        new_word = re.sub(r'[^\\w\\s]', '', word)\n","        if new_word != '':\n","            new_words.append(new_word)\n","    return new_words\n","\n","def remove_stopwords(words):\n","    \"\"\"Remove stop words from list of tokenized words\"\"\"\n","    new_words = []\n","    for word in words:\n","        if word not in stopwords.words('english'):\n","            new_words.append(word)\n","    return new_words\n","\n","def get_wordnet_pos(tag):\n","    tag_dict = {\"J\": wordnet.ADJ,\"N\": wordnet.NOUN,\"V\": wordnet.VERB,\"R\": wordnet.ADV}\n","    return tag_dict.get(tag,wordnet.NOUN)\n","\n","# def lemmatize(words):\n","#     \"\"\"Lemmatize words in list of tokenized words\"\"\"\n","#     lemmatizer = WordNetLemmatizer()\n","#     lemmas = []\n","#     posTagged = nltk.pos_tag(words)\n","#     wordnetTagged = list(map(lambda x: (x[0], get_wordnet_pos(x[1][0])), posTagged))\n","#     for word,tag in wordnetTagged:\n","#       lemma = lemmatizer.lemmatize(word,tag)\n","#       lemmas.append(lemma)\n","#     return lemmas\n","\n","def lemmatizeSpacy(words):\n","  sent = \"\"\n","  lwords = []\n","  for word in words:\n","    sent += word + \" \" \n","  model = spacy.load(\"en_core_web_sm\")\n","  tokens = model(sent)\n","  for i in range(len(tokens)):\n","    lwords.append((tokens[i].lemma_,i+1))\n","  # for token in tokens:\n","  #   lwords.append(token.lemma_)\n","  return lwords\n","\n","def preProcess_html(fileName):\n","    sample = denoise_text(fileName)\n","    sample = replace_contractions(sample)\n","    words = nltk.word_tokenize(sample)\n","    words = remove_non_ascii(words)\n","    words = to_lowercase(words)\n","    words = remove_punctuation(words)\n","    words = lemmatizeSpacy(words)\n","    words = remove_stopwords(words)\n","    # words = lemmatize(words)\n","    # words = lemmatizeSpacy(words)\n","    return words  \n","\n","def clean_text(text):\n","    # text=re.sub('\\w*\\d\\w*','', text)\n","    text=re.sub('\\n',' ',text)\n","    text=re.sub(r\"http\\S+\", \"\", text)\n","    text=re.sub('[^a-z0-9A-Z]',' ',text)\n","    text=re.sub(' +',' ',text)\n","    return text\n","\n","def preProcessotherfiles(fileName):\n","    sample = clean_text(fileName)\n","    sample = replace_contractions(sample)\n","    words = nltk.word_tokenize(sample)\n","    words = remove_non_ascii(words)\n","    words = to_lowercase(words)\n","    words = remove_punctuation(words)\n","    words = remove_stopwords(words)\n","    words = lemmatizeSpacy(words)    \n","    return words \n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTwRbkWFuwTS","executionInfo":{"status":"ok","timestamp":1618085658762,"user_tz":-330,"elapsed":553,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}}},"source":[""],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"eFsKQI7MlBg7","executionInfo":{"status":"ok","timestamp":1618086299034,"user_tz":-330,"elapsed":639304,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}}},"source":["for i in corpus.keys():\n","  if i.endswith(\".html\") or i.endswith(\".header\"):\n","    corpus[i][0] = preProcess_html(corpus[i][0])\n","  else:\n","    corpus[i][0] = preProcessotherfiles(corpus[i][0])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8MS58BBPjf-d","executionInfo":{"status":"ok","timestamp":1618086383190,"user_tz":-330,"elapsed":833,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}},"outputId":"4826b9c5-5565-4639-8068-e78289291174"},"source":["len(corpus.keys())"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["467"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WOsI8P7azn0X","executionInfo":{"status":"ok","timestamp":1618086384886,"user_tz":-330,"elapsed":802,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}},"outputId":"b7f8bd0b-64ce-4df1-d269-05f90414884d"},"source":["print(corpus['life.txt'])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[[('may', 1), ('well', 2), ('start', 3), ('write', 4), ('first', 5), ('writing', 6), ('sort', 7), ('mood', 8), ('secondly', 9), ('topic', 10), ('bother', 11), ('time', 12), ('long', 13), ('since', 14), ('put', 15), ('write', 16), ('sort', 17), ('text', 18), ('file', 19), ('essay', 20), ('subject', 21), ('tonight', 22), ('craving', 23), ('write', 24), ('gather', 25), ('idea', 26), ('settle', 27), ('brain', 28), ('proceed', 29), ('write', 30), ('really', 31), ('exist', 32), ('hell', 33), ('thought', 34), ('run', 35), ('dave', 36), ('mind', 37), ('sit', 38), ('wooden', 39), ('floor', 40), ('room', 41), ('late', 42), ('night', 43), ('exact', 44), ('time', 45), ('sure', 46), ('computer', 47), ('autodiale', 48), ('hack', 49), ('code', 50), ('end', 51), ('room', 52), ('small', 53), ('dias', 54), ('type', 55), ('niche', 56), ('lay', 57), ('keyboard', 58), ('setup', 59), ('various', 60), ('book', 61), ('magazine', 62), ('lie', 63), ('strew', 64), ('title', 65), ('within', 66), ('range', 67), ('keyboard', 68), ('midi', 69), ('dirk', 70), ('gentley', 71), ('holistic', 72), ('detective', 73), ('agency', 74)]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VAHSBjok44PN","executionInfo":{"status":"ok","timestamp":1618086386496,"user_tz":-330,"elapsed":982,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}}},"source":[""],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySq0jJn8oexi","executionInfo":{"status":"ok","timestamp":1618086406786,"user_tz":-330,"elapsed":1039,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}}},"source":["# with open('DocTerms_SpacyLemm.pickle', 'wb') as handle:\n","  # pickle.dump(corpus, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","with open('/content/DocTerms_SpacyLemm.pickle', 'rb') as handle:\n","  docT = pickle.load(handle)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzB7BtfVKu49","executionInfo":{"status":"ok","timestamp":1618086409125,"user_tz":-330,"elapsed":1332,"user":{"displayName":"Jaswanth Naidu","photoUrl":"","userId":"14808420569336844249"}},"outputId":"528abae2-df14-4374-988f-03a652ffc619"},"source":["docT.keys()"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['tree.txt', 'consumdr.hum', 'snow.txt', 'contrad1.hum', 'candle.hum', 'spiders.txt', 'timem.hac', 'aluminum.hum', 'life.txt', 'sight.txt', 'cameloto.hum', 'beyond.hum', 'partya.txt', 'nitepeek.sto', 'blind.txt', 'altside.hum', 'abyss.txt', 't_zone.jok', 'fantas.hum', 'advsayed.txt', 'eyeargon.hum', 'elite.app', 'rocket.sf', 'corcor.hum', 'elveshoe.txt', 'ab40thv.txt', 'gold3ber.txt', 'game.txt', 'excerpt.txt', 'knuckle.txt', 'emperor3.txt', 'empnclot.txt', 'abbey.txt', 'advtthum.txt', 'archive', 'wolfcran.txt', 'immorti.hum', 'wlgirl.txt', 'cooldark.sto', 'wolf7kid.txt', 'vday.hum', 'imagin.hum', 'adv_alad.txt', 'wombat.und', 'gemdra.txt', 'aircon.txt', 'wolflamb.txt', 'testpilo.hum', 'valen', 'confilct.fun', 'narciss.txt', 'enchdup.hum', 'ladylust.hum', 'tcoa.txt', 'enginer.txt', 'encamp01.txt', 'korea.s', 'taxnovel.txt', 'greedog.txt', 'keepmodu.txt', 'vainsong.txt', 'goldgoos.txt', 'quickfix', 'goldbug.poe', 'omarsheh.txt', 'grav', 'empty.txt', 'oxfrog.txt', 'gulliver.txt', 'obstgoat.txt', 'gay', 'ghost', 'goldfish.txt', 'tao3.dos', 'empsjowk.txt', 'enya_trn.txt', 'quot', 'kharian.txt', 'ezoff', 'girlclub.txt', 'tctac.txt', 'gatherng.txt', 'tailbear.txt', 'traitor.txt', 'gloves.txt', 'vampword.txt', 'girl', 'vaincrow.txt', 'enc', 'qcarroll', 'goldenp.txt', 'greatlrn.leg', 'yukon.txt', 'veiledl.txt', 'write', 'unluckwr.txt', 'wrt', 'uglyduck.txt', 'weeprncs.txt', 'lgoldbrd.txt', 'aminegg.txt', 'alissadl.txt', 'antcrick.txt', 'aquith.txt', 'beast.asc', 'bulzork1.txt', 'bulironb.txt', 'bureau.txt', 'beautbst.txt', 'bulphrek.txt', 'bgcspoof.txt', 'bulfelis.txt', 'burintrv.66', 'burltrs', 'burintrv.92', 'burintrv.78', 'rid.txt', 'mindprob.txt', 'lament.txt', 'kzap.txt', 'sucker.txt', 'mike.txt', 'angry_ca.txt', 'asop', 'mario.txt', 'zombies.txt', 'wisteria.txt', 'outcast.dos', 'quest', 'withdraw.cyb', 'beggars.txt', 'buggy.txt', 'blue', 'bishop00.txt', 'bern', 'blackp.txt', 'buldetal.txt', 'bulhuntr.txt', 'blh.txt', 'buldream.txt', 'bulmrx.txt', 'blackrdr', 'blak', 'bulprint.txt', 'bulolli1.txt', 'bulnoopt.txt', 'bulnland.txt', 'bulolli2.txt', 'graymare.txt', 'batlslau.txt', 'blossom.pom', 'bluebrd.txt', 'bullove.txt', 'bumm', 'burn', 's&m_plot', 's&m_that', 'safe', 'arcadia.sty', 'weaver.txt', 'tuc_mees', 'sanpedr2.txt', 'mattress.txt', 'mazarin.txt', 'melissa.txt', 'tearglas.txt', 'thanksg', 'thewave', 'the-tree.txt', 'timetrav.txt', 'tin', 'tinsoldr.txt', 'toilet.s', '13chil.txt', '14.lws', '16.lws', '17.lws', '18.lws', '19.lws', '20.lws', '5orange.txt', '6ablemen.txt', '6napolen.txt', '7oldsamr.txt', '7voysinb.txt', 'musgrave.txt', 'musibrem.txt', 'jackbstl.txt', 'jaynejob.asc', 'jim.asc', '3gables.txt', '3lpigs.txt', '3student.txt', '3wishes.txt', 'radar_ra.txt', 'rainda.txt', 'reap', 'shoscomb.txt', 'shrdfarm.txt', 'shulk.txt', 'sick-kid.txt', 'silverb.txt', 'sis', 'sleprncs.txt', 'snowmaid.txt', 'snowqn1.txt', 'piracy.sto', 'panama.txt', 'paul_har.sto', 'peace.fun', 'wanderer.fun', 'hansgrtl.txt', 'hareleph.txt', 'hareporc.txt', 'haretort.txt', 'stainles.ana', 'angelfur.hum', 'bigred.hum', 'blabnove.hum', 'blabnove.txt', 'brain.damage', 'bulwer.lytton', 'crazy.hum', 'excerpt.hum', 'fantasy.hum', 'fantasy.txt', 'fred.txt', 'hitch2.txt', 'hitch3.txt', 'hotline1.txt', 'hotline3.txt', 'hotline4.txt', 'idi.hum', 'imonly17.txt', 'jerichms.hum', 'fear.hum', 'dakota.txt', 'dan', 'darkness.txt', 'deal', 'bram', 'bran', 'breaks1.asc', 'breaks2.asc', 'breaks3.asc', 'bruce-p.txt', 'lil', 'lionbird', 'lionmane.txt', 'lionmosq.txt', 'lionwar.txt', 'lmermaid.txt', 'lmtchgrl.txt', 'startrek.txt', 'deathmrs.d', 'deer.txt', 'descent.poe', 'diaryflf.txt', 'dicegame.txt', 'dicksong.txt', 'myeyes', 'long1-3.txt', 'lpeargrl.txt', 'lrrhood.txt', 'ltp', 'luf', 'lure.txt', 'fleas.txt', 'flktrp.txt', 'floc', 'floobs.txt', 'flute.txt', 'flytrunk.txt', 'paink-ws.txt', 'parotsha.txt', 'perf', 'mtinder.txt', 'monkking.txt', 'monksol.txt', 'mouslion.txt', 'mindwar', 'missing.txt', 'pussboot.txt', 'pinocch.txt', 'foxncrow.txt', 'foxnstrk.txt', 'mydream.txt', 'cabin.txt', 'cardcnt.txt', 'ccm.txt', 'domain.poe', 'dopedenn.txt', 'dskool.txt', 'dtruck.txt', 'dwar', 'redragon.txt', 'retrib.txt', 'rock', 'roger1.txt', 'running.txt', 'sunday.txt', 'superg1', 'stairdre.txt', 'stsgreek', 'igiv', 'immortal', 'inter', 'adler.txt', 'aesop11.txt', 'aesopa10.txt', 'alad10.txt', 'healer.txt', 'whgdsreg.reg', 'fable.txt', 'space.txt', 'spectacl.poe', 'spider.txt', 'sqzply.txt', 'sre-dark.txt', 'szechuan', 'solitary.txt', 'pregn.txt', 'psf.txt', 'psi', 'psyc', 'plescopm.txt', 'cybersla.txt', 'hole2nar.txt', 'holmesbk.txt', 'home.fil', 'hop-frog.poe', 'horsdonk.txt', 'horswolf.txt', 'hound-b.txt', 'fic1', 'fic2', 'fic3', 'fic4', 'fic5', 'fic7', 'fish.txt', 'frogp.txt', 'island.poe', 'foxngrap.txt', 'fran', 'fea1', 'fea2', 'fea3', 'fearmnky', 'fgoose.txt', 'freeman.fil', 'friend.s', 'friends.txt', 'frum', 'nigel.10', 'nigel.2', 'nigel.3', 'nigel.4', 'nigel.5', 'nigel.6', 'nigel.7', 'nihgel_8.9', 'non2', 'non3', 'non4', 'nigel.1', '4moons.txt', 'telefone.txt', 'hils', 'history5.txt', 'poplstrm.txt', 'pphamlin.txt', 'prince.art', 'progx', 'hell4.txt', 'helmfuse.txt', 'charlie.txt', 'chik', 'clevdonk.txt', 'clon', 'cmoutmou.txt', 'comp', 'crabhern.txt', 'cum', 'wall.art', 'blasters.fic', 'jackmac.fic', 'reality.txt', 'times.fic', 'fourth.fic', 'campfire.txt', 'aislesix.txt', 'bagelman.txt', 'berternie.txt', 'discocanbefun.txt', 'kneeslapper.txt', 'mcdonaldl.txt', 'modemhippy.txt', 'pepdegener.txt', 'socialvikings.txt', 'terrorbears.txt', 'bgb.txt', 'cooldark.txt', 'aisle.six', 'bagel.man', 'cow.exploder', 'curious.george', 'day.in.mcdonald', 'disco.be.fun', 'fowl.death', 'how.ernie.bert', 'keeping.insanit', 'kneeslapper', 'pepsi.degenerat', 'social.vikings', 'spam.key', 'textfile.primer', 'robotech', 'hellmach.txt', '3sonnets.vrs', 'glimpse1.txt', 'bookem2', 'bookem.1', 'bookem3', '100west.txt', 'assorted.txt', 'arctic.txt', 'bestwish', 'forgotte', 'quarter.c1', 'quarter.c10', 'quarter.c11', 'quarter.c12', 'quarter.c13', 'quarter.c14', 'quarter.c15', 'quarter.c16', 'quarter.c17', 'quarter.c18', 'quarter.c19', 'quarter.c2', 'quarter.c3', 'quarter.c4', 'quarter.c5', 'quarter.c6', 'quarter.c7', 'quarter.c8', 'quarter.c9', 'vgilante.txt', 'sre02.txt', 'sre03.txt', 'sretrade.txt', 'sre01.txt', 'sre_feqh.txt', 'sre_sei.txt', 'sre05.txt', 'sre07.txt', 'sre10.txt', 'sre09.txt', 'sre06.txt', 'sre_finl.txt', 'sre08.txt', 'srex.txt', 'sre04.txt', 'poem-1.txt', 'poem-2.txt', 'poem-4.txt'])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"OvzYl30rkd4O"},"source":[""],"execution_count":null,"outputs":[]}]}